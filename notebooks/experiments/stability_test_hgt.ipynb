{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43c4d27",
   "metadata": {},
   "source": [
    "# ðŸ§ª MULTI-SEED STABILITY TEST\n",
    "## Kiá»ƒm tra Ä‘á»™ á»•n Ä‘á»‹nh cá»§a HGT Knowledge Graph Model\n",
    "\n",
    "**Má»¥c tiÃªu:** Cháº¡y model vá»›i 10 seeds khÃ¡c nhau Ä‘á»ƒ Ä‘Ã¡nh giÃ¡:\n",
    "- Mean AUC\n",
    "- Standard Deviation\n",
    "- Confidence Interval\n",
    "- So sÃ¡nh vá»›i ECFP4 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a7800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def canonicalize_smiles(smi):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol:\n",
    "            return Chem.MolToSmiles(mol, canonical=True, isomericSmiles=False)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def scaffold_split_balanced(df, smiles_col='SMILES', test_size=0.2, seed=42):\n",
    "    \"\"\"Scaffold split vá»›i seed cá»‘ Ä‘á»‹nh cho reproducibility\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    scaffold_dict = defaultdict(list)\n",
    "    \n",
    "    for idx, smi in enumerate(df[smiles_col]):\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        try:\n",
    "            scaf = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=False) if mol else \"Generic\"\n",
    "        except:\n",
    "            scaf = \"Generic\"\n",
    "        scaffold_dict[scaf].append(idx)\n",
    "    \n",
    "    groups = sorted(scaffold_dict.values(), key=len, reverse=True)\n",
    "    train_inds, test_inds = [], []\n",
    "    target_test_size = len(df) * test_size\n",
    "    \n",
    "    for group in groups:\n",
    "        if len(test_inds) + len(group) <= target_test_size + 50:\n",
    "            test_inds.extend(group)\n",
    "        else:\n",
    "            train_inds.extend(group)\n",
    "    \n",
    "    return df.iloc[train_inds].copy(), df.iloc[test_inds].copy()\n",
    "\n",
    "def get_ecfp4(smiles_list):\n",
    "    return np.array([np.array(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(s), 2, nBits=1024)) \n",
    "                     for s in smiles_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06408023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. BUILD TRULY INDEPENDENT GRAPHS (STRICT SEPARATION)\n",
    "# =============================================================================\n",
    "# [FIX DATA LEAK] - Complete rewrite to ensure zero overlap\n",
    "\n",
    "def build_independent_graphs(gds, train_mol_ids, test_mol_ids, seed):\n",
    "    \"\"\"\n",
    "    Build COMPLETELY INDEPENDENT train and test graphs\n",
    "    \n",
    "    CRITICAL CHANGES:\n",
    "    1. Train graph contains ONLY train molecules + their connections\n",
    "    2. Test graph contains ONLY test molecules + their connections\n",
    "    3. Shared entities (Scaffold, Target, etc.) use SAME features BUT different local indices\n",
    "    4. NO topology leakage - graphs are disjoint\n",
    "    \"\"\"\n",
    "    # ==================== SANITY CHECK ====================\n",
    "    # [FIX DATA LEAK] - Verify no overlap\n",
    "    overlap = set(train_mol_ids) & set(test_mol_ids)\n",
    "    assert len(overlap) == 0, f\"âŒ LEAKAGE DETECTED: {len(overlap)} overlapping molecules!\"\n",
    "    \n",
    "    # ==================== LOAD ALL ENTITIES ====================\n",
    "    all_molecules = gds.run_cypher(\"\"\"\n",
    "        MATCH (n:Molecule) WHERE n.is_virtual = false\n",
    "        RETURN id(n) as node_id, n.smiles as smiles\n",
    "    \"\"\")\n",
    "    \n",
    "    scaffolds = gds.run_cypher(\"MATCH (n:Scaffold) RETURN id(n) as node_id, n.smiles as smiles\")\n",
    "    targets = gds.run_cypher(\"MATCH (n:Target) RETURN id(n) as node_id, n.name as name\")\n",
    "    functional_groups = gds.run_cypher(\"MATCH (n:FunctionalGroup) RETURN id(n) as node_id, n.name as name\")\n",
    "    warheads = gds.run_cypher(\"MATCH (n:Warhead) RETURN id(n) as node_id, n.name as name\")\n",
    "    moas = gds.run_cypher(\"MATCH (n:MoA) RETURN id(n) as node_id, n.name as name\")\n",
    "    \n",
    "    # ==================== LOAD ALL EDGES ====================\n",
    "    all_edges = gds.run_cypher(\"\"\"\n",
    "        MATCH (m)-[r]->(n)\n",
    "        WHERE (m:Molecule AND m.is_virtual = false) OR (n:Molecule AND n.is_virtual = false)\n",
    "        RETURN id(m) as src, type(r) as rel_type, id(n) as dst, \n",
    "               labels(m)[0] as src_type, labels(n)[0] as dst_type\n",
    "    \"\"\")\n",
    "    \n",
    "    # ==================== SPLIT MOLECULES ====================\n",
    "    train_molecules = all_molecules[all_molecules['node_id'].isin(train_mol_ids)].reset_index(drop=True)\n",
    "    test_molecules = all_molecules[all_molecules['node_id'].isin(test_mol_ids)].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"   âœ… Train: {len(train_molecules)} mols, Test: {len(test_molecules)} mols\")\n",
    "    \n",
    "    # ==================== INITIALIZE SHARED FEATURES ====================\n",
    "    # [FIX DATA LEAK] - Features are shared BUT indices are separate\n",
    "    torch.manual_seed(seed)\n",
    "    embed_dim = 128\n",
    "    \n",
    "    # Global feature matrices (SAME for both graphs)\n",
    "    global_scaffold_feats = torch.randn(len(scaffolds), embed_dim)\n",
    "    global_target_feats = torch.randn(len(targets), embed_dim)\n",
    "    global_fg_feats = torch.randn(len(functional_groups), embed_dim)\n",
    "    global_wh_feats = torch.randn(len(warheads), embed_dim)\n",
    "    global_moa_feats = torch.randn(len(moas), embed_dim)\n",
    "    \n",
    "    # Global ID to feature index mapping\n",
    "    global_scaf_map = {row['node_id']: i for i, row in scaffolds.iterrows()}\n",
    "    global_targ_map = {row['node_id']: i for i, row in targets.iterrows()}\n",
    "    global_fg_map = {row['node_id']: i for i, row in functional_groups.iterrows()}\n",
    "    global_wh_map = {row['node_id']: i for i, row in warheads.iterrows()}\n",
    "    global_moa_map = {row['node_id']: i for i, row in moas.iterrows()}\n",
    "    \n",
    "    # ==================== BUILD TRAIN GRAPH ====================\n",
    "    train_data = HeteroData()\n",
    "    \n",
    "    # LOCAL indexing for train molecules\n",
    "    train_mol_local_map = {row['node_id']: i for i, row in train_molecules.iterrows()}\n",
    "    \n",
    "    # Collect entities actually connected to train molecules\n",
    "    train_connected_entities = {\n",
    "        'Scaffold': set(), 'Target': set(), 'FunctionalGroup': set(),\n",
    "        'Warhead': set(), 'MoA': set()\n",
    "    }\n",
    "    \n",
    "    # Filter edges to train graph only\n",
    "    train_edges = []\n",
    "    for _, row in all_edges.iterrows():\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        # [FIX DATA LEAK] - CRITICAL: Skip ANY edge touching test molecules\n",
    "        if src_type == 'Molecule' and src_id not in train_mol_local_map:\n",
    "            continue\n",
    "        if dst_type == 'Molecule' and dst_id not in train_mol_local_map:\n",
    "            continue\n",
    "        \n",
    "        # Track connected entities\n",
    "        if src_type != 'Molecule':\n",
    "            train_connected_entities[src_type].add(src_id)\n",
    "        if dst_type != 'Molecule':\n",
    "            train_connected_entities[dst_type].add(dst_id)\n",
    "        \n",
    "        train_edges.append(row)\n",
    "    \n",
    "    # Create LOCAL mappings for shared entities in train graph\n",
    "    train_scaf_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['Scaffold']))}\n",
    "    train_targ_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['Target']))}\n",
    "    train_fg_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['FunctionalGroup']))}\n",
    "    train_wh_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['Warhead']))}\n",
    "    train_moa_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['MoA']))}\n",
    "    \n",
    "    # Set features (select from global features)\n",
    "    train_data['Molecule'].x = torch.randn(len(train_molecules), embed_dim)\n",
    "    train_data['Scaffold'].x = global_scaffold_feats[[global_scaf_map[gid] for gid in sorted(train_connected_entities['Scaffold'])]]\n",
    "    train_data['Target'].x = global_target_feats[[global_targ_map[gid] for gid in sorted(train_connected_entities['Target'])]]\n",
    "    train_data['FunctionalGroup'].x = global_fg_feats[[global_fg_map[gid] for gid in sorted(train_connected_entities['FunctionalGroup'])]]\n",
    "    train_data['Warhead'].x = global_wh_feats[[global_wh_map[gid] for gid in sorted(train_connected_entities['Warhead'])]]\n",
    "    train_data['MoA'].x = global_moa_feats[[global_moa_map[gid] for gid in sorted(train_connected_entities['MoA'])]]\n",
    "    \n",
    "    # Build train edges with local indices\n",
    "    train_edge_dict = defaultdict(lambda: [[], []])\n",
    "    train_local_maps = {\n",
    "        'Molecule': train_mol_local_map,\n",
    "        'Scaffold': train_scaf_local,\n",
    "        'Target': train_targ_local,\n",
    "        'FunctionalGroup': train_fg_local,\n",
    "        'Warhead': train_wh_local,\n",
    "        'MoA': train_moa_local\n",
    "    }\n",
    "    \n",
    "    for row in train_edges:\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        if src_id not in train_local_maps[src_type] or dst_id not in train_local_maps[dst_type]:\n",
    "            continue\n",
    "        \n",
    "        src_idx = train_local_maps[src_type][src_id]\n",
    "        dst_idx = train_local_maps[dst_type][dst_id]\n",
    "        \n",
    "        key = (src_type, row['rel_type'], dst_type)\n",
    "        train_edge_dict[key][0].append(src_idx)\n",
    "        train_edge_dict[key][1].append(dst_idx)\n",
    "        \n",
    "        # Reverse edges\n",
    "        rev_key = (dst_type, f\"rev_{row['rel_type']}\", src_type)\n",
    "        train_edge_dict[rev_key][0].append(dst_idx)\n",
    "        train_edge_dict[rev_key][1].append(src_idx)\n",
    "    \n",
    "    for key, (srcs, dsts) in train_edge_dict.items():\n",
    "        train_data[key].edge_index = torch.tensor([srcs, dsts], dtype=torch.long)\n",
    "    \n",
    "    # ==================== BUILD TEST GRAPH (SAME PROCESS) ====================\n",
    "    test_data = HeteroData()\n",
    "    \n",
    "    test_mol_local_map = {row['node_id']: i for i, row in test_molecules.iterrows()}\n",
    "    \n",
    "    test_connected_entities = {\n",
    "        'Scaffold': set(), 'Target': set(), 'FunctionalGroup': set(),\n",
    "        'Warhead': set(), 'MoA': set()\n",
    "    }\n",
    "    \n",
    "    test_edges = []\n",
    "    for _, row in all_edges.iterrows():\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        # [FIX DATA LEAK] - CRITICAL: Skip ANY edge touching train molecules\n",
    "        if src_type == 'Molecule' and src_id not in test_mol_local_map:\n",
    "            continue\n",
    "        if dst_type == 'Molecule' and dst_id not in test_mol_local_map:\n",
    "            continue\n",
    "        \n",
    "        if src_type != 'Molecule':\n",
    "            test_connected_entities[src_type].add(src_id)\n",
    "        if dst_type != 'Molecule':\n",
    "            test_connected_entities[dst_type].add(dst_id)\n",
    "        \n",
    "        test_edges.append(row)\n",
    "    \n",
    "    test_scaf_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['Scaffold']))}\n",
    "    test_targ_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['Target']))}\n",
    "    test_fg_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['FunctionalGroup']))}\n",
    "    test_wh_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['Warhead']))}\n",
    "    test_moa_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['MoA']))}\n",
    "    \n",
    "    test_data['Molecule'].x = torch.randn(len(test_molecules), embed_dim)\n",
    "    test_data['Scaffold'].x = global_scaffold_feats[[global_scaf_map[gid] for gid in sorted(test_connected_entities['Scaffold'])]]\n",
    "    test_data['Target'].x = global_target_feats[[global_targ_map[gid] for gid in sorted(test_connected_entities['Target'])]]\n",
    "    test_data['FunctionalGroup'].x = global_fg_feats[[global_fg_map[gid] for gid in sorted(test_connected_entities['FunctionalGroup'])]]\n",
    "    test_data['Warhead'].x = global_wh_feats[[global_wh_map[gid] for gid in sorted(test_connected_entities['Warhead'])]]\n",
    "    test_data['MoA'].x = global_moa_feats[[global_moa_map[gid] for gid in sorted(test_connected_entities['MoA'])]]\n",
    "    \n",
    "    test_edge_dict = defaultdict(lambda: [[], []])\n",
    "    test_local_maps = {\n",
    "        'Molecule': test_mol_local_map,\n",
    "        'Scaffold': test_scaf_local,\n",
    "        'Target': test_targ_local,\n",
    "        'FunctionalGroup': test_fg_local,\n",
    "        'Warhead': test_wh_local,\n",
    "        'MoA': test_moa_local\n",
    "    }\n",
    "    \n",
    "    for row in test_edges:\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        if src_id not in test_local_maps[src_type] or dst_id not in test_local_maps[dst_type]:\n",
    "            continue\n",
    "        \n",
    "        src_idx = test_local_maps[src_type][src_id]\n",
    "        dst_idx = test_local_maps[dst_type][dst_id]\n",
    "        \n",
    "        key = (src_type, row['rel_type'], dst_type)\n",
    "        test_edge_dict[key][0].append(src_idx)\n",
    "        test_edge_dict[key][1].append(dst_idx)\n",
    "        \n",
    "        rev_key = (dst_type, f\"rev_{row['rel_type']}\", src_type)\n",
    "        test_edge_dict[rev_key][0].append(dst_idx)\n",
    "        test_edge_dict[rev_key][1].append(src_idx)\n",
    "    \n",
    "    for key, (srcs, dsts) in test_edge_dict.items():\n",
    "        test_data[key].edge_index = torch.tensor([srcs, dsts], dtype=torch.long)\n",
    "    \n",
    "    print(f\"   âœ… Train edges: {sum(len(e[0]) for e in train_edge_dict.values())}, Test edges: {sum(len(e[0]) for e in test_edge_dict.values())}\")\n",
    "    \n",
    "    return train_data, test_data, train_mol_local_map, test_mol_local_map, train_molecules, test_molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06408023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. BUILD TRULY INDEPENDENT GRAPHS (STRICT SEPARATION)\n",
    "# =============================================================================\n",
    "# [FIX DATA LEAK] - Complete rewrite to ensure zero overlap\n",
    "\n",
    "def build_independent_graphs(gds, train_mol_ids, test_mol_ids, seed):\n",
    "    \"\"\"\n",
    "    Build COMPLETELY INDEPENDENT train and test graphs\n",
    "    \n",
    "    CRITICAL CHANGES:\n",
    "    1. Train graph contains ONLY train molecules + their connections\n",
    "    2. Test graph contains ONLY test molecules + their connections\n",
    "    3. Shared entities (Scaffold, Target, etc.) use SAME features BUT different local indices\n",
    "    4. NO topology leakage - graphs are disjoint\n",
    "    \"\"\"\n",
    "    # ==================== SANITY CHECK ====================\n",
    "    # [FIX DATA LEAK] - Verify no overlap\n",
    "    overlap = set(train_mol_ids) & set(test_mol_ids)\n",
    "    assert len(overlap) == 0, f\"âŒ LEAKAGE DETECTED: {len(overlap)} overlapping molecules!\"\n",
    "    \n",
    "    # ==================== LOAD ALL ENTITIES ====================\n",
    "    all_molecules = gds.run_cypher(\"\"\"\n",
    "        MATCH (n:Molecule) WHERE n.is_virtual = false\n",
    "        RETURN id(n) as node_id, n.smiles as smiles\n",
    "    \"\"\")\n",
    "    \n",
    "    scaffolds = gds.run_cypher(\"MATCH (n:Scaffold) RETURN id(n) as node_id, n.smiles as smiles\")\n",
    "    targets = gds.run_cypher(\"MATCH (n:Target) RETURN id(n) as node_id, n.name as name\")\n",
    "    functional_groups = gds.run_cypher(\"MATCH (n:FunctionalGroup) RETURN id(n) as node_id, n.name as name\")\n",
    "    warheads = gds.run_cypher(\"MATCH (n:Warhead) RETURN id(n) as node_id, n.name as name\")\n",
    "    moas = gds.run_cypher(\"MATCH (n:MoA) RETURN id(n) as node_id, n.name as name\")\n",
    "    \n",
    "    # ==================== LOAD ALL EDGES ====================\n",
    "    all_edges = gds.run_cypher(\"\"\"\n",
    "        MATCH (m)-[r]->(n)\n",
    "        WHERE (m:Molecule AND m.is_virtual = false) OR (n:Molecule AND n.is_virtual = false)\n",
    "        RETURN id(m) as src, type(r) as rel_type, id(n) as dst, \n",
    "               labels(m)[0] as src_type, labels(n)[0] as dst_type\n",
    "    \"\"\")\n",
    "    \n",
    "    # ==================== SPLIT MOLECULES ====================\n",
    "    train_molecules = all_molecules[all_molecules['node_id'].isin(train_mol_ids)].reset_index(drop=True)\n",
    "    test_molecules = all_molecules[all_molecules['node_id'].isin(test_mol_ids)].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"   âœ… Train: {len(train_molecules)} mols, Test: {len(test_molecules)} mols\")\n",
    "    \n",
    "    # ==================== INITIALIZE SHARED FEATURES ====================\n",
    "    # [FIX DATA LEAK] - Features are shared BUT indices are separate\n",
    "    torch.manual_seed(seed)\n",
    "    embed_dim = 128\n",
    "    \n",
    "    # Global feature matrices (SAME for both graphs)\n",
    "    global_scaffold_feats = torch.randn(len(scaffolds), embed_dim)\n",
    "    global_target_feats = torch.randn(len(targets), embed_dim)\n",
    "    global_fg_feats = torch.randn(len(functional_groups), embed_dim)\n",
    "    global_wh_feats = torch.randn(len(warheads), embed_dim)\n",
    "    global_moa_feats = torch.randn(len(moas), embed_dim)\n",
    "    \n",
    "    # Global ID to feature index mapping\n",
    "    global_scaf_map = {row['node_id']: i for i, row in scaffolds.iterrows()}\n",
    "    global_targ_map = {row['node_id']: i for i, row in targets.iterrows()}\n",
    "    global_fg_map = {row['node_id']: i for i, row in functional_groups.iterrows()}\n",
    "    global_wh_map = {row['node_id']: i for i, row in warheads.iterrows()}\n",
    "    global_moa_map = {row['node_id']: i for i, row in moas.iterrows()}\n",
    "    \n",
    "    # ==================== BUILD TRAIN GRAPH ====================\n",
    "    train_data = HeteroData()\n",
    "    \n",
    "    # LOCAL indexing for train molecules\n",
    "    train_mol_local_map = {row['node_id']: i for i, row in train_molecules.iterrows()}\n",
    "    \n",
    "    # Collect entities actually connected to train molecules\n",
    "    train_connected_entities = {\n",
    "        'Scaffold': set(), 'Target': set(), 'FunctionalGroup': set(),\n",
    "        'Warhead': set(), 'MoA': set()\n",
    "    }\n",
    "    \n",
    "    # Filter edges to train graph only\n",
    "    train_edges = []\n",
    "    for _, row in all_edges.iterrows():\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        # [FIX DATA LEAK] - CRITICAL: Skip ANY edge touching test molecules\n",
    "        if src_type == 'Molecule' and src_id not in train_mol_local_map:\n",
    "            continue\n",
    "        if dst_type == 'Molecule' and dst_id not in train_mol_local_map:\n",
    "            continue\n",
    "        \n",
    "        # Track connected entities\n",
    "        if src_type != 'Molecule':\n",
    "            train_connected_entities[src_type].add(src_id)\n",
    "        if dst_type != 'Molecule':\n",
    "            train_connected_entities[dst_type].add(dst_id)\n",
    "        \n",
    "        train_edges.append(row)\n",
    "    \n",
    "    # Create LOCAL mappings for shared entities in train graph\n",
    "    train_scaf_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['Scaffold']))}\n",
    "    train_targ_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['Target']))}\n",
    "    train_fg_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['FunctionalGroup']))}\n",
    "    train_wh_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['Warhead']))}\n",
    "    train_moa_local = {gid: i for i, gid in enumerate(sorted(train_connected_entities['MoA']))}\n",
    "    \n",
    "    # Set features (select from global features)\n",
    "    train_data['Molecule'].x = torch.randn(len(train_molecules), embed_dim)\n",
    "    train_data['Scaffold'].x = global_scaffold_feats[[global_scaf_map[gid] for gid in sorted(train_connected_entities['Scaffold'])]]\n",
    "    train_data['Target'].x = global_target_feats[[global_targ_map[gid] for gid in sorted(train_connected_entities['Target'])]]\n",
    "    train_data['FunctionalGroup'].x = global_fg_feats[[global_fg_map[gid] for gid in sorted(train_connected_entities['FunctionalGroup'])]]\n",
    "    train_data['Warhead'].x = global_wh_feats[[global_wh_map[gid] for gid in sorted(train_connected_entities['Warhead'])]]\n",
    "    train_data['MoA'].x = global_moa_feats[[global_moa_map[gid] for gid in sorted(train_connected_entities['MoA'])]]\n",
    "    \n",
    "    # Build train edges with local indices\n",
    "    train_edge_dict = defaultdict(lambda: [[], []])\n",
    "    train_local_maps = {\n",
    "        'Molecule': train_mol_local_map,\n",
    "        'Scaffold': train_scaf_local,\n",
    "        'Target': train_targ_local,\n",
    "        'FunctionalGroup': train_fg_local,\n",
    "        'Warhead': train_wh_local,\n",
    "        'MoA': train_moa_local\n",
    "    }\n",
    "    \n",
    "    for row in train_edges:\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        if src_id not in train_local_maps[src_type] or dst_id not in train_local_maps[dst_type]:\n",
    "            continue\n",
    "        \n",
    "        src_idx = train_local_maps[src_type][src_id]\n",
    "        dst_idx = train_local_maps[dst_type][dst_id]\n",
    "        \n",
    "        key = (src_type, row['rel_type'], dst_type)\n",
    "        train_edge_dict[key][0].append(src_idx)\n",
    "        train_edge_dict[key][1].append(dst_idx)\n",
    "        \n",
    "        # Reverse edges\n",
    "        rev_key = (dst_type, f\"rev_{row['rel_type']}\", src_type)\n",
    "        train_edge_dict[rev_key][0].append(dst_idx)\n",
    "        train_edge_dict[rev_key][1].append(src_idx)\n",
    "    \n",
    "    for key, (srcs, dsts) in train_edge_dict.items():\n",
    "        train_data[key].edge_index = torch.tensor([srcs, dsts], dtype=torch.long)\n",
    "    \n",
    "    # ==================== BUILD TEST GRAPH (SAME PROCESS) ====================\n",
    "    test_data = HeteroData()\n",
    "    \n",
    "    test_mol_local_map = {row['node_id']: i for i, row in test_molecules.iterrows()}\n",
    "    \n",
    "    test_connected_entities = {\n",
    "        'Scaffold': set(), 'Target': set(), 'FunctionalGroup': set(),\n",
    "        'Warhead': set(), 'MoA': set()\n",
    "    }\n",
    "    \n",
    "    test_edges = []\n",
    "    for _, row in all_edges.iterrows():\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        # [FIX DATA LEAK] - CRITICAL: Skip ANY edge touching train molecules\n",
    "        if src_type == 'Molecule' and src_id not in test_mol_local_map:\n",
    "            continue\n",
    "        if dst_type == 'Molecule' and dst_id not in test_mol_local_map:\n",
    "            continue\n",
    "        \n",
    "        if src_type != 'Molecule':\n",
    "            test_connected_entities[src_type].add(src_id)\n",
    "        if dst_type != 'Molecule':\n",
    "            test_connected_entities[dst_type].add(dst_id)\n",
    "        \n",
    "        test_edges.append(row)\n",
    "    \n",
    "    test_scaf_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['Scaffold']))}\n",
    "    test_targ_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['Target']))}\n",
    "    test_fg_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['FunctionalGroup']))}\n",
    "    test_wh_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['Warhead']))}\n",
    "    test_moa_local = {gid: i for i, gid in enumerate(sorted(test_connected_entities['MoA']))}\n",
    "    \n",
    "    test_data['Molecule'].x = torch.randn(len(test_molecules), embed_dim)\n",
    "    test_data['Scaffold'].x = global_scaffold_feats[[global_scaf_map[gid] for gid in sorted(test_connected_entities['Scaffold'])]]\n",
    "    test_data['Target'].x = global_target_feats[[global_targ_map[gid] for gid in sorted(test_connected_entities['Target'])]]\n",
    "    test_data['FunctionalGroup'].x = global_fg_feats[[global_fg_map[gid] for gid in sorted(test_connected_entities['FunctionalGroup'])]]\n",
    "    test_data['Warhead'].x = global_wh_feats[[global_wh_map[gid] for gid in sorted(test_connected_entities['Warhead'])]]\n",
    "    test_data['MoA'].x = global_moa_feats[[global_moa_map[gid] for gid in sorted(test_connected_entities['MoA'])]]\n",
    "    \n",
    "    test_edge_dict = defaultdict(lambda: [[], []])\n",
    "    test_local_maps = {\n",
    "        'Molecule': test_mol_local_map,\n",
    "        'Scaffold': test_scaf_local,\n",
    "        'Target': test_targ_local,\n",
    "        'FunctionalGroup': test_fg_local,\n",
    "        'Warhead': test_wh_local,\n",
    "        'MoA': test_moa_local\n",
    "    }\n",
    "    \n",
    "    for row in test_edges:\n",
    "        src_type, dst_type = row['src_type'], row['dst_type']\n",
    "        src_id, dst_id = row['src'], row['dst']\n",
    "        \n",
    "        if src_id not in test_local_maps[src_type] or dst_id not in test_local_maps[dst_type]:\n",
    "            continue\n",
    "        \n",
    "        src_idx = test_local_maps[src_type][src_id]\n",
    "        dst_idx = test_local_maps[dst_type][dst_id]\n",
    "        \n",
    "        key = (src_type, row['rel_type'], dst_type)\n",
    "        test_edge_dict[key][0].append(src_idx)\n",
    "        test_edge_dict[key][1].append(dst_idx)\n",
    "        \n",
    "        rev_key = (dst_type, f\"rev_{row['rel_type']}\", src_type)\n",
    "        test_edge_dict[rev_key][0].append(dst_idx)\n",
    "        test_edge_dict[rev_key][1].append(src_idx)\n",
    "    \n",
    "    for key, (srcs, dsts) in test_edge_dict.items():\n",
    "        test_data[key].edge_index = torch.tensor([srcs, dsts], dtype=torch.long)\n",
    "    \n",
    "    print(f\"   âœ… Train edges: {sum(len(e[0]) for e in train_edge_dict.values())}, Test edges: {sum(len(e[0]) for e in test_edge_dict.values())}\")\n",
    "    \n",
    "    return train_data, test_data, train_mol_local_map, test_mol_local_map, train_molecules, test_molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0882d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸš€ MULTI-SEED STABILITY TEST (CORRECTED - NO LEAKAGE)\n",
      "   Testing 10 seeds\n",
      "================================================================================\n",
      "\n",
      "âœ… FIXES APPLIED:\n",
      "   1. Scaffold split BEFORE graph construction\n",
      "   2. Completely independent train/test graphs\n",
      "   3. Self-supervised pretraining (NO label leakage)\n",
      "   4. FROZEN encoder for test inference\n",
      "   5. Sanity checks (permutation + random baseline)\n",
      "================================================================================\n",
      "\n",
      "[1/10] Seed = 42\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 42\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3851\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3833\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3789\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3732\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3662\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9575, ACC: 0.8808\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9164, ACC: 0.8405\n",
      "  ðŸ” Sanity: Permuted=0.5400, Random=0.4940\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[2/10] Seed = 123\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 123\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3851\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3834\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3791\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3747\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3688\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9550, ACC: 0.8808\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9806, ACC: 0.9245\n",
      "  ðŸ” Sanity: Permuted=0.5358, Random=0.5039\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[3/10] Seed = 456\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 456\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3846\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3819\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3780\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3714\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3656\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9584, ACC: 0.8816\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9776, ACC: 0.9185\n",
      "  ðŸ” Sanity: Permuted=0.5321, Random=0.4974\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[4/10] Seed = 789\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 789\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3843\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3798\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3745\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3701\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3610\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9552, ACC: 0.8782\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9776, ACC: 0.9220\n",
      "  ðŸ” Sanity: Permuted=0.5174, Random=0.5089\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[5/10] Seed = 101112\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 101112\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3847\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3823\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3777\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3718\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3653\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9553, ACC: 0.8696\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9640, ACC: 0.8834\n",
      "  ðŸ” Sanity: Permuted=0.5594, Random=0.5157\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[6/10] Seed = 131415\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 131415\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3846\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3823\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3769\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3724\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3675\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9524, ACC: 0.8688\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9694, ACC: 0.8979\n",
      "  ðŸ” Sanity: Permuted=0.4846, Random=0.4835\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[7/10] Seed = 161718\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 161718\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3850\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3827\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3788\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3714\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3643\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9573, ACC: 0.8799\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9085, ACC: 0.8233\n",
      "  ðŸ” Sanity: Permuted=0.4498, Random=0.5265\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[8/10] Seed = 192021\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 192021\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3850\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3826\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3779\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3729\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3664\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9549, ACC: 0.8696\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9720, ACC: 0.9108\n",
      "  ðŸ” Sanity: Permuted=0.4610, Random=0.5315\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[9/10] Seed = 222324\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 222324\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3846\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3823\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3772\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3720\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3628\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9560, ACC: 0.8765\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9870, ACC: 0.9322\n",
      "  ðŸ” Sanity: Permuted=0.4371, Random=0.5032\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "[10/10] Seed = 252627\n",
      "\n",
      "============================================================\n",
      "ðŸŽ² Seed = 252627\n",
      "============================================================\n",
      "  ðŸ”€ Split: Train=4478, Test=1166\n",
      "   âœ… Train: 4478 mols, Test: 1166 mols\n",
      "   âœ… Train edges: 164694, Test edges: 41818\n",
      "    Epoch 10/50 | Self-Supervised Loss: 1.3846\n",
      "    Epoch 20/50 | Self-Supervised Loss: 1.3822\n",
      "    Epoch 30/50 | Self-Supervised Loss: 1.3763\n",
      "    Epoch 40/50 | Self-Supervised Loss: 1.3718\n",
      "    Epoch 50/50 | Self-Supervised Loss: 1.3651\n",
      "  ðŸ“Š ECFP4       -> AUC: 0.9550, ACC: 0.8816\n",
      "  ðŸ“Š HGT (SS)    -> AUC: 0.9545, ACC: 0.8808\n",
      "  ðŸ” Sanity: Permuted=0.4581, Random=0.5076\n",
      "  âœ… Graphs are independent (NO leakage)\n",
      "\n",
      "âœ… All experiments completed!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. RUN MULTI-SEED EXPERIMENTS\n",
    "# =============================================================================\n",
    "# [FIX DATA LEAK] - Keep same, but now calls corrected pipeline\n",
    "\n",
    "# Load data once\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df[df['Final_Label'] != 'Uncertain']\n",
    "df['Label_Num'] = df['Final_Label'].apply(lambda x: 1 if str(x).lower() == 'active' else 0)\n",
    "df['SMILES_Key'] = df['SMILES'].apply(canonicalize_smiles)\n",
    "df = df.dropna(subset=['SMILES_Key']).drop_duplicates(subset=['SMILES_Key'])\n",
    "\n",
    "gds = GraphDataScience(NEO4J_URI, auth=NEO4J_AUTH)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸš€ MULTI-SEED STABILITY TEST (CORRECTED - NO LEAKAGE)\")\n",
    "print(f\"   Testing {len(TEST_SEEDS)} seeds\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ… FIXES APPLIED:\")\n",
    "print(\"   1. Scaffold split BEFORE graph construction\")\n",
    "print(\"   2. Completely independent train/test graphs\")\n",
    "print(\"   3. Self-supervised pretraining (NO label leakage)\")\n",
    "print(\"   4. FROZEN encoder for test inference\")\n",
    "print(\"   5. Sanity checks (permutation + random baseline)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run experiments\n",
    "results = []\n",
    "for i, seed in enumerate(TEST_SEEDS, 1):\n",
    "    print(f\"\\n[{i}/{len(TEST_SEEDS)}] Seed = {seed}\")\n",
    "    result = run_single_experiment(seed, gds, df, verbose=True)\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nâœ… All experiments completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc0853",
   "metadata": {},
   "source": [
    "## Ká»‹ch báº£n thuyáº¿t trÃ¬nh (Slide: Stability Analysis â€“ Multi-seed)\n",
    "\n",
    "**(Má»Ÿ Ä‘áº§u â€“ 10â€“15s)**\n",
    "- Dáº¡ em xin trÃ¬nh bÃ y slide Ä‘Ã¡nh giÃ¡ **Ä‘á»™ á»•n Ä‘á»‹nh theo nhiá»u seed** cá»§a mÃ´ hÃ¬nh HGT trÃªn Knowledge Graph, vÃ  so sÃ¡nh vá»›i baseline **ECFP4**.\n",
    "- Má»¥c tiÃªu cá»§a pháº§n nÃ y lÃ  kiá»ƒm tra: khi thay Ä‘á»•i seed (khá»Ÿi táº¡o/ngáº«u nhiÃªn), hiá»‡u nÄƒng AUC-ROC **dao Ä‘á»™ng nhiá»u hay Ã­t**.\n",
    "\n",
    "**(Bá»‘i cáº£nh thÃ­ nghiá»‡m â€“ 20â€“30s)**\n",
    "- Em cháº¡y cÃ¹ng má»™t pipeline vÃ  cÃ¹ng cÃ¡ch chia dá»¯ liá»‡u (scaffold split) nhÆ°ng thay **10 seeds** khÃ¡c nhau.\n",
    "- Má»—i seed cho ra má»™t giÃ¡ trá»‹ **AUC-ROC** cho 2 phÆ°Æ¡ng phÃ¡p: **ECFP4** vÃ  **KG/HGT**.\n",
    "- á»ž Ä‘Ã¢y em táº­p trung vÃ o hai Ã½: (1) má»©c AUC trung bÃ¬nh vÃ  (2) **Ä‘á»™ á»•n Ä‘á»‹nh** thá»ƒ hiá»‡n qua phÃ¢n phá»‘i vÃ  Ä‘á»™ lá»‡ch chuáº©n.\n",
    "\n",
    "**(Giáº£i thÃ­ch biá»ƒu Ä‘á»“ â€“ Ä‘i theo 4 Ã´, 60â€“90s)**\n",
    "1) **Ã” trÃªn-trÃ¡i: Violin plot â€“ AUC Distribution Across Seeds**\n",
    "- Biá»ƒu Ä‘á»“ nÃ y cho tháº¥y **phÃ¢n phá»‘i AUC** theo 10 seed cho tá»«ng phÆ°Æ¡ng phÃ¡p.\n",
    "- Pháº§n violin cÃ ng â€œdÃ yâ€ á»Ÿ Ä‘Ã¢u thÃ¬ AUC hay rÆ¡i vÃ o vÃ¹ng Ä‘Ã³; Ä‘á»“ng thá»i nhÃ¬n Ä‘Æ°á»£c Ä‘á»™ tráº£i rá»™ng.\n",
    "- Em nháº¥n máº¡nh: ECFP4 cÃ³ phÃ¢n phá»‘i **ráº¥t háº¹p** â†’ á»•n Ä‘á»‹nh; cÃ²n KG cÃ³ phÃ¢n phá»‘i **rá»™ng hÆ¡n** â†’ nháº¡y hÆ¡n vá»›i seed.\n",
    "\n",
    "2) **Ã” trÃªn-pháº£i: AUC Across Different Seeds (theo tá»«ng seed)**\n",
    "- Má»—i Ä‘iá»ƒm lÃ  má»™t seed (S1â€¦S10).\n",
    "- ÄÆ°á»ng ECFP4 gáº§n nhÆ° pháº³ng â†’ thay seed gáº§n nhÆ° khÃ´ng Ä‘á»•i.\n",
    "- ÄÆ°á»ng KG dao Ä‘á»™ng rÃµ hÆ¡n vÃ  cÃ³ seed tá»¥t máº¡nh hÆ¡n cÃ¡c seed cÃ²n láº¡i â†’ cho tháº¥y rá»§i ro â€œhÃªn xuiâ€ theo khá»Ÿi táº¡o hoáº·c quÃ¡ trÃ¬nh há»c.\n",
    "\n",
    "3) **Ã” dÆ°á»›i-trÃ¡i: Box plot + Ä‘iá»ƒm tá»«ng seed (AUC Stability)**\n",
    "- Box plot tÃ³m táº¯t trung vá»‹ vÃ  khoáº£ng tá»© phÃ¢n vá»‹; cÃ¡c Ä‘iá»ƒm Ä‘á»/xanh lÃ  káº¿t quáº£ tá»«ng seed.\n",
    "- ECFP4: cÃ¡c Ä‘iá»ƒm tá»¥ láº¡i, há»™p ráº¥t gá»n.\n",
    "- KG: há»™p vÃ  whisker rá»™ng hÆ¡n, cÃ³ Ä‘iá»ƒm lá»‡ch nhiá»u â†’ thá»ƒ hiá»‡n variance cao hÆ¡n.\n",
    "\n",
    "4) **Ã” dÆ°á»›i-pháº£i: Standard Deviation (Lower is better)**\n",
    "- ÄÃ¢y lÃ  tÃ³m táº¯t Ä‘á»‹nh lÆ°á»£ng: **Ä‘á»™ lá»‡ch chuáº©n AUC** cá»§a má»—i phÆ°Æ¡ng phÃ¡p.\n",
    "- ECFP4 cÃ³ std ráº¥t tháº¥p (trong slide Ä‘ang hiá»ƒn thá»‹ khoáº£ng ~0.0017), cÃ²n KG cao hÆ¡n Ä‘Ã¡ng ká»ƒ (khoáº£ng ~0.0271).\n",
    "- Káº¿t luáº­n tá»« Ã´ nÃ y: xÃ©t riÃªng vá» **stability**, ECFP4 tá»‘t hÆ¡n; KG cáº§n cáº£i thiá»‡n Ä‘á»ƒ káº¿t quáº£ nháº¥t quÃ¡n hÆ¡n.\n",
    "\n",
    "**(Káº¿t luáº­n & thÃ´ng Ä‘iá»‡p chá»‘t â€“ 20â€“30s)**\n",
    "- Slide nÃ y tráº£ lá»i cÃ¢u há»i: â€œMÃ´ hÃ¬nh cÃ³ á»•n Ä‘á»‹nh khÃ´ng khi Ä‘á»•i seed?â€\n",
    "- Káº¿t quáº£: **ECFP4 á»•n Ä‘á»‹nh**, cÃ²n **KG/HGT cÃ³ thá»ƒ Ä‘áº¡t AUC tá»‘t** nhÆ°ng **dao Ä‘á»™ng theo seed** tÆ°Æ¡ng Ä‘á»‘i lá»›n.\n",
    "- HÆ°á»›ng cáº£i thiá»‡n em Ä‘á» xuáº¥t: cá»‘ Ä‘á»‹nh/kiá»ƒm soÃ¡t nguá»“n ngáº«u nhiÃªn ká»¹ hÆ¡n, tinh chá»‰nh hyperparameter, regularization/early stopping á»•n Ä‘á»‹nh hÆ¡n, vÃ  bÃ¡o cÃ¡o thÃªm meanÂ±CI trÃªn nhiá»u seed Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ´ng báº±ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322a233d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 8. VISUALIZATION (NO CHANGES)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# --- Plot 1: AUC Distribution (Violin Plot) ---\u001b[39;00m\n\u001b[0;32m      8\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. VISUALIZATION (NO CHANGES)\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# --- Plot 1: AUC Distribution (Violin Plot) ---\n",
    "ax1 = axes[0, 0]\n",
    "data_plot = pd.melt(results_df[['auc_ecfp', 'auc_kg']], \n",
    "                     var_name='Method', value_name='AUC')\n",
    "data_plot['Method'] = data_plot['Method'].map({'auc_ecfp': 'ECFP4', 'auc_kg': 'KG'})\n",
    "sns.violinplot(data=data_plot, x='Method', y='AUC', ax=ax1, palette=['skyblue', 'salmon'])\n",
    "ax1.set_title('AUC Distribution Across Seeds', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('AUC-ROC', fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# --- Plot 2: Seed-by-Seed Comparison ---\n",
    "ax2 = axes[0, 1]\n",
    "x = np.arange(len(results_df))\n",
    "ax2.plot(x, results_df['auc_ecfp'], marker='o', label='ECFP4', color='blue', linewidth=2)\n",
    "ax2.plot(x, results_df['auc_kg'], marker='s', label='KG', color='red', linewidth=2)\n",
    "ax2.fill_between(x, results_df['auc_ecfp'], alpha=0.2, color='blue')\n",
    "ax2.fill_between(x, results_df['auc_kg'], alpha=0.2, color='red')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels([f\"S{i+1}\" for i in range(len(results_df))], rotation=45)\n",
    "ax2.set_xlabel('Seed Index', fontsize=12)\n",
    "ax2.set_ylabel('AUC-ROC', fontsize=12)\n",
    "ax2.set_title('AUC Across Different Seeds', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# --- Plot 3: Box Plot with Individual Points ---\n",
    "ax3 = axes[1, 0]\n",
    "bp = ax3.boxplot([results_df['auc_ecfp'], results_df['auc_kg']], \n",
    "                   labels=['ECFP4', 'KG'], patch_artist=True,\n",
    "                   boxprops=dict(facecolor='lightgray', alpha=0.7))\n",
    "for i, (method, color) in enumerate([('auc_ecfp', 'blue'), ('auc_kg', 'red')], 1):\n",
    "    y = results_df[method]\n",
    "    x = np.random.normal(i, 0.04, size=len(y))\n",
    "    ax3.scatter(x, y, alpha=0.6, color=color, s=50, zorder=3)\n",
    "ax3.set_ylabel('AUC-ROC', fontsize=12)\n",
    "ax3.set_title('AUC Stability (Box Plot)', fontsize=14, fontweight='bold')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# --- Plot 4: Standard Deviation Comparison ---\n",
    "ax4 = axes[1, 1]\n",
    "methods = ['ECFP4', 'KG']\n",
    "stds = [results_df['auc_ecfp'].std(), results_df['auc_kg'].std()]\n",
    "colors = ['skyblue', 'salmon']\n",
    "bars = ax4.bar(methods, stds, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax4.set_ylabel('Standard Deviation', fontsize=12)\n",
    "ax4.set_title('Stability Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, std in zip(bars, stds):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{std:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('stability_analysis_corrected.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¾ Plot saved as 'stability_analysis_corrected.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egfr_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
